{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a898bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>duration</th>\n",
       "      <th>close</th>\n",
       "      <th>transactions</th>\n",
       "      <th>volumeUsd</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31 15:45:00</td>\n",
       "      <td>899999</td>\n",
       "      <td>95440.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.892188e+07</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31 16:00:00</td>\n",
       "      <td>899999</td>\n",
       "      <td>95507.0</td>\n",
       "      <td>2399</td>\n",
       "      <td>2.121718e+07</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31 16:15:00</td>\n",
       "      <td>899999</td>\n",
       "      <td>95020.0</td>\n",
       "      <td>1705</td>\n",
       "      <td>2.155068e+07</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31 16:30:00</td>\n",
       "      <td>899999</td>\n",
       "      <td>94901.0</td>\n",
       "      <td>2254</td>\n",
       "      <td>1.898660e+07</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31 16:45:00</td>\n",
       "      <td>899999</td>\n",
       "      <td>94902.0</td>\n",
       "      <td>981</td>\n",
       "      <td>1.046999e+07</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    t  duration    close  transactions     volumeUsd symbol\n",
       "0 2024-12-31 15:45:00    899999  95440.0          2024  1.892188e+07    BTC\n",
       "1 2024-12-31 16:00:00    899999  95507.0          2399  2.121718e+07    BTC\n",
       "2 2024-12-31 16:15:00    899999  95020.0          1705  2.155068e+07    BTC\n",
       "3 2024-12-31 16:30:00    899999  94901.0          2254  1.898660e+07    BTC\n",
       "4 2024-12-31 16:45:00    899999  94902.0           981  1.046999e+07    BTC"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df['duration'] = df['close_timestamp'] - df['open_timestamp']\n",
    "# Approximate candle volume as mean price * contracts traded\n",
    "df['volumeUsd'] = df['volume'] * (df['close'] + df['open']) / 2 \n",
    "df['t'] = pd.to_datetime(df['open_timestamp'], unit='ms')\n",
    "df = df[['t', 'duration', 'close', 'transactions', 'volumeUsd', 'symbol']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2b4cc",
   "metadata": {},
   "source": [
    "## lstm\n",
    "\n",
    "The purpose of this notebook is to fit a LSTM model to predict the future returns of a futures contract (ENA), given information about the market (volume and technicals) and the indexes (BTC, ETH).\n",
    "\n",
    "We will be formatting the data accordingly before fitting an LSTM model to some training set of data, and then evaluating the predictive power of this model on a testing set of data to validate whether it is useful.\n",
    "\n",
    "This is simply a training exercise, we don't recommend using this code for anything more than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d458952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by symbol to calculate the required technical indicators\n",
    "grouped = df.groupby('symbol')\n",
    "timeframes = [1, 2, 4, 8, 16]\n",
    "\n",
    "def compute_indicators(group):\n",
    "    for tf in timeframes:\n",
    "        group[f'return_{tf}'] = group['close'].pct_change(periods=tf)\n",
    "        group[f'volume_change_{tf}'] = group['volumeUsd'].diff(periods=tf)\n",
    "        if tf != 1:\n",
    "            group[f'ema_volume_{tf}'] = group['volumeUsd'].ewm(span=tf, adjust=False).mean()\n",
    "    \n",
    "    return group\n",
    "\n",
    "tdf = grouped.apply(compute_indicators)\n",
    "\n",
    "# tdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aea50e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tdf.drop(['duration', 'close', 'transactions'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "btc = tdf.loc['BTC']\n",
    "eth = tdf.loc['ETH']\n",
    "ena = tdf.loc['ENA']\n",
    "\n",
    "# Take 60% of the data for training\n",
    "train_split_index = 3 * ena.shape[0] // 5\n",
    "train_split_time = ena.iloc[train_split_index]['t']\n",
    "\n",
    "# Rename all columns to add asset prefix\n",
    "btc = btc.rename(columns=lambda col: f'btc_{col}' if col != 't' else 't')\n",
    "eth = eth.rename(columns=lambda col: f'eth_{col}' if col != 't' else 't')\n",
    "ena = ena.rename(columns=lambda col: f'ena_{col}' if col != 't' else 't')\n",
    "\n",
    "df = btc.merge(eth, on='t', how='outer').merge(ena, on='t', how='outer')\n",
    "\n",
    "# Specify explicitly the feature which is our Y dependent variable\n",
    "df['Y'] = df['ena_return_2'].shift(-2)\n",
    "\n",
    "# Perform a train-test split of the data on the given split time\n",
    "df_train, df_test = df.loc[df.t <= train_split_time], df.loc[df.t > train_split_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c094c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (\n",
    "    [f'{asset}_return_{i}' for asset in ['btc', 'eth', 'ena'] for i in timeframes] + \n",
    "    [f'{asset}_volume_change_{i}' for asset in ['ena'] for i in timeframes] + \n",
    "    [f'{asset}_ema_volume_{i}' for asset in ['ena'] for i in timeframes if i != 1]\n",
    ")\n",
    "\n",
    "df_train = df_train[['t'] + features + ['Y']]\n",
    "\n",
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cf040ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 20\n",
    "X_ = df_train[features].values\n",
    "Y_ = df_train[\"Y\"].values\n",
    "\n",
    "X, y = [], []\n",
    "num_samples = (len(df_train) - sequence_length)\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    X.append(X_[i : i + sequence_length])\n",
    "    y.append(Y_[i + sequence_length])\n",
    "\n",
    "# Cast X and Y to numpy objects\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c09fdfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2965, 20, 24]) torch.Size([2965])\n",
      "torch.Size([2372, 20, 24]) torch.Size([593, 20, 24])\n",
      "DataLoaders created successfully.\n"
     ]
    }
   ],
   "source": [
    "X_tensor = torch.tensor(X, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "\n",
    "print(X_tensor.shape, y_tensor.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(X_train.shape, X_val.shape)  # Confirm shapes\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 64  # Define batch size\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39bc6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=50, num_layers=2, dropout=0.2):\n",
    "        super(LSTMForecast, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,\n",
    "                           batch_first=True,\n",
    "                            dropout=dropout)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        last_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        out = self.fc(last_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3996c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "input_dim = X_train.shape[2]   # number of features (should be 4 in our case)\n",
    "model = LSTMForecast(input_size=input_dim, hidden_size=10, num_layers=2, dropout=0.2)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()                          # Mean Squared Error loss for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1cbc308e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Training MSE: 0.000271\n",
      "Epoch 20/50, Training MSE: 0.000185\n",
      "Epoch 30/50, Training MSE: 0.000167\n",
      "Epoch 40/50, Training MSE: 0.000165\n",
      "Epoch 50/50, Training MSE: 0.000167\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # set model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass: compute prediction\n",
    "        pred = model(batch_X)             # pred shape: (batch, 1)\n",
    "        pred = pred.squeeze(1)            # squeeze to (batch,) to match batch_y shape\n",
    "        \n",
    "        loss = criterion(pred, batch_y)   # MSE loss between predicted and actual returns\n",
    "        \n",
    "        # Backpropagation and optimization step\n",
    "        optimizer.zero_grad()             # reset gradients from previous step\n",
    "        loss.backward()                   # compute gradients of loss w.r.t. model parameters\n",
    "        optimizer.step()                  # update parameters\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_loader)       # average loss over all batches\n",
    "    \n",
    "    # Print loss every 10 epochs (or every epoch if desired)\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training MSE: {epoch_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb9ed28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.000157, Train RMSE: 0.012522\n",
      "Validation MSE: 0.000149, Validation RMSE: 0.012225, Validation R^2: -0.039\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # switch to evaluation mode (disables dropout, etc.)\n",
    "with torch.no_grad():  # no_grad disables gradient computations, for speed\n",
    "    # Predict on training data (to assess fit) and test data\n",
    "    train_pred = model(X_train).squeeze(1).numpy()\n",
    "    val_pred = model(X_val).squeeze(1).numpy()\n",
    "    Y_train_true = y_train.numpy()\n",
    "    Y_val_true = y_val.numpy()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred)**2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - ss_res/ss_tot\n",
    "\n",
    "train_mse = np.mean((Y_train_true - train_pred)**2)\n",
    "val_mse  = np.mean((Y_val_true - val_pred)**2)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "val_rmse  = np.sqrt(val_mse)\n",
    "val_r2 = r2_score(Y_val_true, val_pred)\n",
    "\n",
    "print(f\"Train MSE: {train_mse:.6f}, Train RMSE: {train_rmse:.6f}\")\n",
    "print(f\"Validation MSE: {val_mse:.6f}, Validation RMSE: {val_rmse:.6f}, Validation R^2: {val_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb08a06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5075885328836425"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Y_val_true * val_pred > 0, 1, 0).sum() / len(Y_val_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "137e873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.933912e-04, Test RMSE: 0.013907, Test R^2: -0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_9968\\1550012899.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 20\n",
    "\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "X_ = df_test[features].values\n",
    "Y_ = df_test[\"Y\"].values\n",
    "\n",
    "X, y = [], []\n",
    "num_samples = (len(df_test) - sequence_length)\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    X.append(X_[i : i + sequence_length])\n",
    "    y.append(Y_[i + sequence_length])\n",
    "\n",
    "# Cast X and Y to numpy objects\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "\n",
    "model.eval()  # switch to evaluation mode (disables dropout, etc.)\n",
    "with torch.no_grad():  # no_grad disables gradient computations, for speed\n",
    "    # Predict on training data (to assess fit) and test data\n",
    "    test_pred = model(X_tensor).squeeze(1).numpy()\n",
    "    Y_test_true = y_tensor.numpy()\n",
    "\n",
    "test_mse  = np.mean((Y_test_true - test_pred)**2)\n",
    "test_rmse  = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(Y_test_true, test_pred)\n",
    "\n",
    "print(f\"Test MSE: {test_mse:.6e}, Test RMSE: {test_rmse:.6f}, Test R^2: {test_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d39f319e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00085968, -0.0045571 , -0.00128107, ...,  0.00175717,\n",
       "        0.00066167,  0.00079842], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2797631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
